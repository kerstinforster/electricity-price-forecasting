{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd562df",
   "metadata": {},
   "source": [
    "# Automated Workflow for ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998213b7",
   "metadata": {},
   "source": [
    "First approach for an automated workflow consisting in data splitting, preprocessing, training, hyperparameter tuning and testing <b> specifically for ML models generated with keras </b>. Since no automated pipelines exist (or at least I could not find one) for using keras ML models for time-series forecasting that can be specified according to our requirements, most of the functions used are customized. <br>\n",
    "\n",
    "<b>Already implemented:</b>\n",
    "* Data splitting (Train-Val / Test) according to specified split date\n",
    "* Conversion to supervised learning problem for ML models\n",
    "* Rolling Window Forward Validation splitting (\"Schnaubelt, Matthias. A comparison of machine learning model validation schemes for non-stationary time series data\")\n",
    "* Grid search for hyperparameter tuning and selection of best model according to minimum RMSE\n",
    "* Retraining of final model on entire dataset and evaluating accuracy using RMSE, MSE, MAPE\n",
    "* First test for 1-hour ahead forecasts and 3 tuneable hyperparameters to check basic functionality and plausibility of results\n",
    "\n",
    "<b>To do:</b>\n",
    "* Integrate with \"live\" data\n",
    "* Include additional data sources\n",
    "* Generate plots for hyperparameter optimization and final testing\n",
    "* Include additional performance metrics: sMAPE to resolve issues with MAPE, perhaps some scaled metrics\n",
    "* Include additional evaluation methods: Diebold-Mariano tests and/or residual diagnostics, efficiency (total number of FLOPs)\n",
    "* Consider execution time of hyperparameter optimization (perhaps decrease number of folds)\n",
    "* Test with all tunable hyperparameters\n",
    "* Tests for 1-day and 1-week ahead forecasts\n",
    "* Test/integrate with other ML models (RNN, LSTM, GRU, SVR, hybrid models, ...)\n",
    "\n",
    "<b>Requirements:</b>\n",
    "pandas,\n",
    "numpy,\n",
    "matplotlib,\n",
    "sklearn,\n",
    "math,\n",
    "keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb68e38",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from csv (for development purposes, TO DO: integrate with montel data + external data)\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.Time\n",
    "Y = data.Value\n",
    "\n",
    "# Get information on min/max dates and number of datapoints \n",
    "datapoints = X.index.max()+1\n",
    "date_min = X.min()\n",
    "date_max = X.max()\n",
    "\n",
    "print('Number of datapoints in the Dataset: {}'.format(datapoints))\n",
    "print('Minimum date from data set: {}'.format(date_min))\n",
    "print('Maximum date from data set: {}'.format(date_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ceda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466214f",
   "metadata": {},
   "source": [
    "## Generate Hourly, Daily, Weekly Data for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe with datetime index\n",
    "data_hourly = data.set_index('Time')\n",
    "data_hourly.index = pd.date_range(date_min,date_max,freq='H')\n",
    "\n",
    "# Resample dataframes for testing of different temporal resolutions\n",
    "data_daily = data_hourly.resample('1D').mean()\n",
    "data_weekly = data_hourly.resample('1W').mean()\n",
    "data_monthly = data_hourly.resample('1M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f467cd9",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data_daily.plot(linewidth=0.1, figsize=(20,5))\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Electricity Price [â‚¬/MWh]')\n",
    "ax.set_title('EEX Day-Ahead Market')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963ccb4",
   "metadata": {},
   "source": [
    "## Preprocessing and Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0bb5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df_datetime, split_date):\n",
    "    '''\n",
    "    Splits dataframe into a training/validation set and a test set according to a specified split date.\n",
    "    df_datetime: pandas.core.frame.DataFrame\n",
    "    split_date: str in the format 'YYYY-MM-DD hh:mm:ss'\n",
    "    \n",
    "    '''\n",
    "    df_train_val = df_datetime.loc[df_datetime.index < split_date]\n",
    "    df_test = df_datetime.loc[df_datetime.index >= split_date]\n",
    "    return df_train_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DATE = '2019-06-01 00:00:00'\n",
    "\n",
    "df_train_val, df_test = train_val_test_split(data_hourly, SPLIT_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ecf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397d950",
   "metadata": {},
   "source": [
    "## Rolling Window Forward Validation Split for Hyperparameter Optimization"
   ]
  },
  {
   "attachments": {
    "rolling_window_forward_validation.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ecfb68a2",
   "metadata": {},
   "source": [
    "![rolling_window_forward_validation.PNG](attachment:rolling_window_forward_validation.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d498f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2matrix(data_arr, look_back, gap):\n",
    "    '''\n",
    "    Converts value array into features (X) and response (Y) to create a supervised learning problem needed for ML mdoels.\n",
    "    data_arr: numpy.ndarray, shape: (#timesteps,) \n",
    "    look_back: int, determines how many timesteps are used for making a prediction (#features per sample)\n",
    "    gap: int, determines how far into the future predictions are made (one hour: gap=0, 1 day: gap=23, 1 week: gap=167)\n",
    "    '''\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data_arr)-look_back):\n",
    "        d=i+look_back  \n",
    "        X.append(data_arr[i:d])\n",
    "        Y.append(data_arr[d+gap])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(num_folds, quot_train, X_train_val, Y_train_val):\n",
    "    '''\n",
    "    Creates folds for rolling window forward validation according to \"Schnaubelt, Matthias. A comparison of machine learning model validation schemes for non-stationary time series data\".\n",
    "    num_folds: int, specifies number of folds used for validation\n",
    "    quot_train: float, specifies the percentage of training data in each fold\n",
    "    X_train_val: numpy.ndarray, shape: (#timesteps, look_back)\n",
    "    Y_train_val: numpy.ndarray, shape: (#timesteps,)\n",
    "    '''\n",
    "    ratio = int(quot_train/(1-quot_train))\n",
    "\n",
    "    len_val = int(np.shape(X_train_val)[0]/(num_folds+ratio))\n",
    "    len_train = int(np.shape(X_train_val)[0]-num_folds*len_val)\n",
    "    len_fold = len_train + len_val\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "\n",
    "    for i in range(num_folds):\n",
    "        X_train.append(X_train_val[i*len_val:i*len_val+len_train]) \n",
    "        Y_train.append(Y_train_val[i*len_val:i*len_val+len_train])\n",
    "        X_val.append(X_train_val[i*len_val+len_train:i*len_val+len_fold])\n",
    "        Y_val.append(Y_train_val[i*len_val+len_train:i*len_val+len_fold])\n",
    "        \n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c64811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to numpy arrays for keras DNN\n",
    "data_train_val = df_train_val.to_numpy()[:,0]\n",
    "data_test = df_test.to_numpy()[:,0]\n",
    "\n",
    "# Setup look_back window and gap in forecast horzion\n",
    "look_back = 30\n",
    "gap = 0 # one-hour ahead forecast: gap = 0, 1 day ahead forecast: gap = 23, 1 week ahead forecast: gap = 167\n",
    "\n",
    "# Transform to supervised learning problem for compatibility with keras ML models\n",
    "X_train_val, Y_train_val = convert2matrix(data_train_val, look_back, gap)\n",
    "X_test, Y_test = convert2matrix(data_test, look_back, gap)\n",
    "\n",
    "# Create multiple folds of train and validation data splits for rolling window forward validation (see paper 5)\n",
    "num_folds = 5\n",
    "quot_train = 0.8\n",
    "\n",
    "X_train, Y_train, X_val, Y_val = create_folds(num_folds, quot_train, X_train_val, Y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32955e",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from keras.activations import relu, elu\n",
    "from keras.metrics import RootMeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "#from keras_flops import get_flops\n",
    "\n",
    "# Initialize early stopping to combat overfitting\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1160aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    '''\n",
    "    Calculates customized metric sMAPE as improvement of the classic MAPE.\n",
    "    TO DO: integrate in keras model API\n",
    "    '''\n",
    "    return np.mean(200*abs(y_true-y_pred)/(y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84eda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dnn(params, metrics, look_back):\n",
    "    '''\n",
    "    Initializes a keras DNN with two hidden layers.\n",
    "    params: <class 'dict'>, combination of hyperparameters from specified parameter grid\n",
    "    metrics: list, implemented so far are RMSE, MAE, MAPE\n",
    "    look_back: int, necessary for dimension of input neuron\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=look_back,\n",
    "                    activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'],\n",
    "                    activation=params['activation']))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss='mse', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e621f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_forward_validation_score(model, params, X_train, Y_train, X_val, Y_val):\n",
    "    '''\n",
    "    Calculates the metrics specified in the model initialization (currently RMSE, MAE, MAPE) for each fold.\n",
    "    Returns the means of the specified metrics over all folds. \n",
    "    \n",
    "    model: keras.engine.sequential.Sequential\n",
    "    params: <class 'dict'>, combination of hyperparameters from specified parameter grid\n",
    "    X_train: list, shape: (num_folds, len_train, look_back)\n",
    "    Y_train: list, shape: (num_folds, len_train)\n",
    "    X_val: list, shape: (num_folds, len_val, look_back)\n",
    "    Y_val: list, shape: (num_folds, len_val)\n",
    "    '''\n",
    "    max_abs_scaler = MaxAbsScaler()\n",
    "    cv_scores = []\n",
    "    for i in range(num_folds):\n",
    "        X_train_prepro = max_abs_scaler.fit_transform(X_train[i])\n",
    "        X_val_prepro = max_abs_scaler.transform(X_val[i])\n",
    "        history = model.fit(X_train_prepro, Y_train[i], epochs=params['epochs'], verbose=1, callbacks=[early_stopping], shuffle = False)\n",
    "        score = model.evaluate(X_val_prepro, Y_val[i], verbose=0)\n",
    "        #print(score)\n",
    "        cv_scores.append(score)\n",
    "        #print(cv_scores)\n",
    "    return np.mean(cv_scores,0)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_rmse_results(rwfv_scores, param_configs):\n",
    "    '''\n",
    "    Determines the configuration yielding the minimum RMSE. \n",
    "    Returns index of minimum RMSE, value of minimum RMSE and the corresponding parameter configuration.\n",
    "    \n",
    "    rwfv_scores: list\n",
    "    param_configs: list\n",
    "    '''\n",
    "    val_min = float(\"inf\")\n",
    "    \n",
    "    for i in range(len(rwfv_scores)):\n",
    "        if rwfv_scores[i][1] < val_min:\n",
    "            ind_min_rmse = i\n",
    "            val_min = rwfv_scores[i][1]\n",
    "            \n",
    "    best_config = param_configs[ind_min_rmse]\n",
    "    return ind_min_rmse, val_min, best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74336b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_rwfv(grid, metrics, look_back, X_train, Y_train, X_val, Y_val):\n",
    "    '''\n",
    "    Performs a grid search over all possible parameter configurations. \n",
    "    Evaluates each configuration using rolling window forward validation. \n",
    "    Returns the optimum parameter configuration, the index yielding minimum RMSE and the minimum RMSE value itself. \n",
    "    \n",
    "    grid: list, contains all tunable hyperparameters and corresponding values\n",
    "    metrics: list, implemented so far are RMSE, MAE, MAPE\n",
    "    X_train: list, shape: (num_folds, len_train, look_back)\n",
    "    Y_train: list, shape: (num_folds, len_train)\n",
    "    X_val: list, shape: (num_folds, len_val, look_back)\n",
    "    Y_val: list, shape: (num_folds, len_val)\n",
    "    '''\n",
    "    rwfv_scores = []\n",
    "    param_configs = []\n",
    "\n",
    "    # iterate over parameters from grid and calculate RMSE/MAE/MAPE\n",
    "    for params in grid:\n",
    "        # Fit Model\n",
    "        model = model_dnn(params, metrics, look_back)\n",
    "        # Estimate error with rolling window forward validation\n",
    "        rwfv_score = rolling_window_forward_validation_score(model, params, X_train, Y_train, X_val, Y_val)\n",
    "        rwfv_scores.append(rwfv_score)\n",
    "        param_configs.append(params)\n",
    "        #print(rwfv_scores)\n",
    "        #print(param_configs)\n",
    "\n",
    "    # select best hyperparameter config based on minimum rmse\n",
    "    ind_min_rmse, min_rmse, best_config = get_min_rmse_results(rwfv_scores, param_configs)\n",
    "\n",
    "    return best_config, ind_min_rmse, min_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to be optimized in hyperparameter grid\n",
    "param_grid = [{#'lr': (0.5, 5, 10),\n",
    "     'first_neuron':[4, 8, 16, 32, 64, 128],\n",
    "     'second_neuron':[4, 8, 16, 32, 64, 128],\n",
    "     #'hidden_layers':[0, 1, 2],\n",
    "     #'batch_size': [2, 10, 30],\n",
    "     'epochs': [10, 25, 50, 100], \n",
    "     'dropout': [0, 0.1, 0.25, 0.5, 0.75, 1],\n",
    "     #'kernel_initializer': ['uniform','normal'],\n",
    "     #'optimizer': ['Nadam', 'Adam'],\n",
    "     #'losses': ['mean_squared_error', 'binary_crossentropy'],\n",
    "     'activation':['relu', 'elu', 'tanh', 'softmax']}]\n",
    "\n",
    "# Grid for testing the workflow with reduced number of options\n",
    "test_grid = [{'first_neuron':[4, 32],\n",
    "     'second_neuron':[4, 32],\n",
    "     'epochs': [10], \n",
    "     'dropout': [0, 0.5],\n",
    "     'activation':['relu', 'elu']}]\n",
    "\n",
    "#grid = list(ParameterGrid(param_grid))\n",
    "grid = list(ParameterGrid(test_grid))\n",
    "\n",
    "metrics = [RootMeanSquaredError(), MeanAbsoluteError(), MeanAbsolutePercentageError()]\n",
    "\n",
    "best_config, ind_min_rmse, min_rmse = grid_search_rwfv(grid, metrics, look_back, X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "print(\"Minimum RMSE: \", \"%.2f\" % min_rmse)\n",
    "print(\"Parameter configuration yielding minimum RMSE: \", best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26513b",
   "metadata": {},
   "source": [
    "## Retrain Model on Entire Training/Validation Dataset and Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d032170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify evaulation metrics\n",
    "metrics_test = [RootMeanSquaredError(), MeanAbsoluteError(), MeanAbsolutePercentageError()]\n",
    "\n",
    "# Initialize model with optimal config\n",
    "best_model = model_dnn(best_config, metrics_test, look_back)\n",
    "\n",
    "# Apply appropriate scaling\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "X_train_val_prepro = max_abs_scaler.fit_transform(X_train_val)\n",
    "X_test_prepro = max_abs_scaler.transform(X_test)\n",
    "\n",
    "# Fit model on entire training/validation dataset\n",
    "history = best_model.fit(X_train_val_prepro, Y_train_val, epochs=best_config['epochs'], verbose=1, callbacks=[early_stopping], shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate final model on the held-out test set\n",
    "final_score = best_model.evaluate(X_test_prepro, Y_test, verbose=0)[1:]\n",
    "print(\"Final RMSE:\", \"%.2f\" % final_score[0])\n",
    "print(\"Final MAE:\", \"%.2f\" % final_score[1])\n",
    "print(\"Final MAPE:\", \"%.2f\" % final_score[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4e73d",
   "metadata": {},
   "source": [
    "## TO DO: Diebold-Mariano-Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3dec06",
   "metadata": {},
   "source": [
    "## TO DO: Residual Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d59d1c",
   "metadata": {},
   "source": [
    "## TO DO: Efficiency (Total Number of FLOPs)\n",
    "Implement FLOP count, e.g. with keras-flops get_flops\n",
    "https://pypi.org/project/keras-flops/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc898fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
